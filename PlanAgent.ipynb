{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7ca206-98f5-4f18-98e1-8344def5c1e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
      "Collecting text-generation\n",
      "  Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m924.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numexpr\n",
      "  Downloading numexpr-2.10.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (405 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.0/405.0 KB\u001b[0m \u001b[31m649.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchainhub\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m641.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/vishnusharma7/.local/lib/python3.10/site-packages (3.1.4)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 KB\u001b[0m \u001b[31m673.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.23.0\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 KB\u001b[0m \u001b[31m688.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<0.4,>=0.3.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from langchain-huggingface) (0.3.6)\n",
      "Collecting tokenizers>=0.19.1\n",
      "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m648.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers>=2.6.0\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 KB\u001b[0m \u001b[31m836.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>2 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from text-generation) (2.9.2)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.8 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from text-generation) (3.10.8)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 KB\u001b[0m \u001b[31m756.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/vishnusharma7/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2\n",
      "  Downloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from jinja2) (2.1.5)\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:20\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/vishnusharma7/.local/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from aiohttp<4.0,>=3.8->text-generation) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from aiohttp<4.0,>=3.8->text-generation) (1.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from aiohttp<4.0,>=3.8->text-generation) (2.4.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from aiohttp<4.0,>=3.8->text-generation) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from aiohttp<4.0,>=3.8->text-generation) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from aiohttp<4.0,>=3.8->text-generation) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from aiohttp<4.0,>=3.8->text-generation) (1.3.1)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 KB\u001b[0m \u001b[31m863.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.1.129)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (8.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from pydantic<3,>2->text-generation) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from pydantic<3,>2->text-generation) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishnusharma7/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m873.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m717.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m374.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m580.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m813.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:17\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m721.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:08\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m999.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.0.0\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m301.4/410.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:01:30\u001b[0m^C\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m301.4/410.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:01:30\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade langchain-groq sentencepiece langchain_huggingface langchain-huggingface text-generation transformers google-search-results numexpr langchainhub sentencepiece jinja2 bitsandbytes langchain-core langchain-anthropic accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "054dca97-1f67-422a-8015-040b6d05c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API keys loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# get the code for loading API keys using .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "HUGGINGFACE_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if not HUGGINGFACE_API_KEY:\n",
    "    print(\"Warning: HUGGINGFACE_API_KEY not found in .env file.\")\n",
    "if not TAVILY_API_KEY:\n",
    "    print(\"Warning: TAVILY_API_KEY not found in .env file.\")\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"Warning: GROQ_API_KEY not found in .env file.\")\n",
    "\n",
    "# You can now use the API keys in your application\n",
    "print(\"API keys loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc2b0cf-599b-4605-a8d2-0aa2d0f68e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"banao2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "61ca9db8-d3b5-44ae-9b43-fe899a601ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e6dd4576-5e9f-4496-b97a-d1919cef8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import logging\n",
    "import operator\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Optional, Annotated, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.constants import Send\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2505fac8-e02e-4170-83d3-858836dc18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class AgentState(BaseModel):\n",
    "#     query: str\n",
    "#     tasks: List[str] = Field(default_factory=list)\n",
    "#     sub_query: Annotated[Dict[str, str], operator.add] = Field(default_factory=dict) \n",
    "#     # Dict[str, str] = Field(default_factory=dict) # you might want to add a reducer here\n",
    "#     answer: str = \"\"\n",
    "#     feedback: Optional[str] = None\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    query: Any  # This is required\n",
    "    tasks: Optional[List[str]] = Field(default_factory=list)  # Optional with default empty list\n",
    "    # sub_query: Optional[Annotated[Dict[str, str], operator.add]] = Field(default_factory=dict)  # Optional with default empty dict\n",
    "    # answer: Optional[str] = \"\"  # Optional with default empty string\n",
    "    feedback: Optional[str] = None  # Optional with None as the default\n",
    "\n",
    "class Perspective(BaseModel):\n",
    "    tasks: List[str] = Field(description=\"Comprehensive list of sub-queries that can be solved indepedently.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39337010-1cd4-4787-8cd5-226456c8c39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "699ceae7-b482-44ed-bfb0-678f55a0c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = \"\"\"\n",
    "You are an advanced AI assistant specialized in analyzing complex queries and breaking them down into smaller, independent sub-queries.\n",
    "Your task is to help users by dividing their main query into manageable parts that can be addressed separately.\n",
    "\n",
    "Input\n",
    "You will receive a main query.\n",
    "\n",
    "Process\n",
    "1. Carefully analyze and comprehend the main query in its entirety.\n",
    "2. Analyze any editorial that has been optinally provided to as {feedback}\n",
    "3. Identify the key components, topics, or steps within the query.\n",
    "4. Determine logical breaking points that allow for independent investigation or resolution.\n",
    "5. Create n sub-queries that collectively cover all aspects of the main query where n is an arbitary number that you need to decide logically.\n",
    "\n",
    "Output\n",
    "Provide a list of n sub-queries, ensuring that:\n",
    "\n",
    "- Each sub-query is clear, concise, and self-contained.\n",
    "- The sub-queries are mutually exclusive to avoid redundancy.\n",
    "- When combined, the sub-queries comprehensively address the main query.\n",
    "- Each sub-query is numbered for easy reference.\n",
    "\n",
    "Guidelines\n",
    "\n",
    "- Maintain the original intent and scope of the main query.\n",
    "- Use simple, straightforward language in the sub-queries.\n",
    "- Avoid making assumptions beyond the information provided in the main query.\n",
    "- If the query cannot be logically divided into the exact number of requested sub-queries, use the closest appropriate number and explain your reasoning.\n",
    "\n",
    "Example\n",
    "Main Query: \"Explain the process of photosynthesis in plants, including the required ingredients, the chemical reactions involved, and the end products.\"\n",
    "\n",
    "Sub-queries:\n",
    "\n",
    "1. What are the essential ingredients required for photosynthesis in plants?\n",
    "2. Describe the main chemical reactions that occur during the process of photosynthesis.\n",
    "3. What are the end products of photosynthesis, and how are they used by the plant?\n",
    "\n",
    "Remember, your goal is to create sub-queries that, when answered, will provide a comprehensive response to the original query.\n",
    "Return the sub_queries in a list format example: [sub_query_1, sub_query_2, sub_query_3] & specify in each sub_query to return the solution.\n",
    "eg. sub_query is \"add 2 and 3\" then the sub_query should be written like \"add 2 and 3 and return the result\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec0b9d6c-fb8e-4cd6-b6b5-fb39c0d5b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def plan_agent(state: AgentState):\n",
    "    system_message = splitter.format(feedback=state.feedback)\n",
    "    # print(system_message) # check how update will be passed here\n",
    "    dict_schema = convert_to_openai_tool(Perspective)\n",
    "    structured_llm = llm.with_structured_output(dict_schema)\n",
    "    response = structured_llm.invoke([{\"role\": \"system\", \"content\": system_message},\n",
    "                              {\"role\": \"user\", \"content\": state.query}])\n",
    "    tasks: List[str] = response['tasks']\n",
    "    state.tasks = tasks\n",
    "    # print(state.tasks)\n",
    "    return {\"tasks\": tasks}\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "604adef6-048e-4d55-a56e-9eca18dc51d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def initialize_agent_state():\n",
    "    query = \"add 2 and 3, multiply 4 and 6, and divide 6 by 2 and return mean of all the answers\"\n",
    "\n",
    "    # List of tasks\n",
    "    tasks = [\n",
    "        \"add 2 and 3\",\n",
    "        \"multiply 4 and 6\",\n",
    "        \"divide 6 by 2\"\n",
    "    ]\n",
    "\n",
    "    # Sub-query breakdown (operation and operands)\n",
    "    sub_query = {\n",
    "        \"addition\": \"2 + 3\",\n",
    "        \"multiplication\": \"4 * 6\",\n",
    "        \"division\": \"6 / 2\"\n",
    "    }\n",
    "\n",
    "    # Perform calculations\n",
    "    add_result = 2 + 3\n",
    "    multiply_result = 4 * 6\n",
    "    divide_result = 6 / 2\n",
    "    mean_result = (add_result + multiply_result + divide_result) / 3\n",
    "\n",
    "    # Initialize the AgentState\n",
    "    agent_state = AgentState(\n",
    "        query=query,\n",
    "        tasks=tasks,\n",
    "        sub_query=sub_query,\n",
    "        answer=str(mean_result),  # Store the mean result as the answer\n",
    "        feedback=None  # No feedback for now\n",
    "    )\n",
    "\n",
    "    return agent_state\n",
    "\n",
    "# Initialize and print the contents of the AgentState\n",
    "state = initialize_agent_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "12005ebe-bce3-4300-88aa-2fd1d767487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 2 and 3 and return the result\n",
      "multiply 4 and 6 and return the result\n",
      "divide 6 by 2 and return the result\n",
      "calculate the mean of the previous results and return the result\n"
     ]
    }
   ],
   "source": [
    "state = AgentState(query=\"add 2 and 3, multiply 4 and 6, and divide 6 by 2 and return mean of all the answers\")\n",
    "plan_agent(state)\n",
    "for task in state.tasks:\n",
    "    print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2eb062a1-9e96-4bbf-8802-bc2d644f5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the Inner loop\n",
    "class Innerloop(MessagesState):\n",
    "    task : str\n",
    "    answer : Annotated[Optional[str], operator.add]\n",
    "    reflect : Optional[str] = None\n",
    "    # feedback : Optinal[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b8ed38f2-b093-428a-93da-18d8e1b0da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def parallelize(state):\n",
    "#     return [Send(\"assistant\", {\n",
    "#         \"innerloop\": Innerloop(\n",
    "#             task=task, \n",
    "#             messages=[HumanMessage(content=f\"solve the task {task}\")]\n",
    "#         )\n",
    "#     }) for task in state.tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6502c632-d858-4c1c-8b8c-3f2b43757ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int):\n",
    "    \"\"\"Adds two integers.\"\"\"\n",
    "    logging.info(f\"Calling add function with {a} and {b}\")\n",
    "    try:\n",
    "        result = a + b\n",
    "        logging.info(f\"Tool returned {result}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error encountered on add function {e}\")\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, divide, multiply]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fdf6b18-027d-4688-9dea-8d5e02e3611d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# This is how a tool is invoked, merely calling llm_with_tools does not work!\n",
    "tool_node.invoke({\"messages\": [llm_with_tools.invoke(\"Add 2 and 3\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e8fada48-95a4-4b2a-af8c-39d904210c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = SystemMessage(content=\"You a expert at performing mathematical operations. you will solve the given question & return its answer\")\n",
    "\n",
    "def assistant(state: Innerloop):\n",
    "    # innerloop = Innerloop(task=input_dict['task'])\n",
    "    # pprint(state)\n",
    "    args = llm_with_tools.invoke([sys_msg] + [state['task']])\n",
    "    # state.sub_query[innerloop.task] = answer\n",
    "    response = tool_node.invoke({\"messages\": [args]})\n",
    "    state['answer'] = response['messages'][0].content\n",
    "    print(state['answer'])\n",
    "    return {\"answer\": response['messages'][0].content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7e8ad10b-ecd8-4460-ac05-0942ad623d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflection \n",
    "def reflect_agent(state: Innerloop):\n",
    "    \"\"\"\n",
    "    Enhanced agent responsible for reflecting on the current state,\n",
    "    refining tasks, and self-reflecting on its own output.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Self-reflection\n",
    "    self_reflection = llm.invoke([\n",
    "        HumanMessage(content=f\"\"\"You are an AI tasked with self-reflection. \n",
    "        Given the state:\n",
    "        query : {state['task']}\n",
    "        answer : {state['answer']}\n",
    "        iterations : 1\n",
    "\n",
    "        Critically analyze answer with the corresponding query. Consider the following:\n",
    "        1. Is the answer comprehensive? Does it address all aspects of the query?\n",
    "        2. Is the corresponding answer correct according to the query.\n",
    "        3. Is there any inconsistency or error in the answer?\n",
    "        4. Could the answer be improved in any way?\n",
    "\n",
    "        If you find any issues or potential improvements, provide a suggestion. \n",
    "        If you believe the answer is already optimal, respond with 'Original answer is optimal'.\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # Step 2: Implement changes based on reflection\n",
    "    if self_reflection.content != \"Original answer is optimal\":\n",
    "        final_reflection = self_reflection.content\n",
    "    else:\n",
    "        final_reflection = \"Hit it!\"\n",
    "    \n",
    "    if final_reflection != \"Hit it!\":\n",
    "        input_message = f\"{sys_msg}\\n{state['task']}\\n{state['answer']}\\n{final_reflection}\"\n",
    "        response = llm_with_tools.invoke(input_message)\n",
    "    \n",
    "    return {\"answer\": response}\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e916e276-effd-434a-a963-2d50a6ed126b",
   "metadata": {},
   "source": [
    "def combine_answers(state: AgentState) -> AgentState:\n",
    "    \"\"\" Combine all the answers in the Dictionary & Generate a final comprehensive answer. \"\"\"\n",
    "    context = \" \".join([v for v in state.sub_query.values() if v])\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"context\"],\n",
    "        template=\"\"\"\n",
    "        You are an AI assistant. Here is the main query: \"{query}\".\n",
    "        Below are some relevant sub-answers:\n",
    "        {context}\n",
    "        \n",
    "        Please provide a detailed, natural language answer to the main query based on the sub-answers.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Generate the prompt by filling in the main query and context\n",
    "    prompt = prompt_template.format(query=state.query, context=context)\n",
    "\n",
    "    # Get the LLM's response\n",
    "    llm_response = llm(prompt)\n",
    "\n",
    "    # Store the final answer in the state\n",
    "    state.answer = llm_response\n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3980c182-149d-4f2b-bd1f-e43c479960c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inner loop workflow\n",
    "builder = StateGraph(Innerloop)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"Reflect\", reflect_agent)\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", \"Reflect\")\n",
    "builder.add_edge(\"Reflect\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "sub_graph = builder.compile(checkpointer=memory) # This compilation is for testing purposes only\n",
    "display(Image(sub_graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "902d5505-c4a5-4429-be9c-d20f276f0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Event: {'messages': [], 'task': 'Add 2 and 3', 'answer': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1s7c', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 673, 'total_tokens': 691, 'completion_time': 0.024, 'prompt_time': 0.175180069, 'queue_time': 0.002021569000000001, 'total_time': 0.199180069}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c6f2ffa4-c312-46cf-a4e3-5e06afc42139-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_1s7c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 673, 'output_tokens': 18, 'total_tokens': 691})}\n",
      "Event Keys: dict_keys(['messages', 'task', 'answer'])\n",
      "messages: []\n",
      "task: Add 2 and 3\n",
      "answer: content='' additional_kwargs={'tool_calls': [{'id': 'call_1s7c', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 673, 'total_tokens': 691, 'completion_time': 0.024, 'prompt_time': 0.175180069, 'queue_time': 0.002021569000000001, 'total_time': 0.199180069}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c6f2ffa4-c312-46cf-a4e3-5e06afc42139-0' tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_1s7c', 'type': 'tool_call'}] usage_metadata={'input_tokens': 673, 'output_tokens': 18, 'total_tokens': 691}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Calling add function with 2 and 3\n",
      "INFO:root:Tool returned 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Full Event: {'messages': [], 'task': 'Add 2 and 3', 'answer': '5'}\n",
      "Event Keys: dict_keys(['messages', 'task', 'answer'])\n",
      "messages: []\n",
      "task: Add 2 and 3\n",
      "answer: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Event: {'messages': [], 'task': 'Add 2 and 3', 'answer': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_axay', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 673, 'total_tokens': 691, 'completion_time': 0.024, 'prompt_time': 0.137621705, 'queue_time': 0.002289041999999991, 'total_time': 0.161621705}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-76808f69-eae9-4c90-a847-9bd2f2b4cfc1-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_axay', 'type': 'tool_call'}], usage_metadata={'input_tokens': 673, 'output_tokens': 18, 'total_tokens': 691})}\n",
      "Event Keys: dict_keys(['messages', 'task', 'answer'])\n",
      "messages: []\n",
      "task: Add 2 and 3\n",
      "answer: content='' additional_kwargs={'tool_calls': [{'id': 'call_axay', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 673, 'total_tokens': 691, 'completion_time': 0.024, 'prompt_time': 0.137621705, 'queue_time': 0.002289041999999991, 'total_time': 0.161621705}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-76808f69-eae9-4c90-a847-9bd2f2b4cfc1-0' tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_axay', 'type': 'tool_call'}] usage_metadata={'input_tokens': 673, 'output_tokens': 18, 'total_tokens': 691}\n"
     ]
    }
   ],
   "source": [
    "sub_state = Innerloop(task=\"Add 2 and 3\")\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in sub_graph.stream(sub_state, thread, stream_mode=\"values\"):\n",
    "    print(\"Full Event:\", event)\n",
    "\n",
    "    # If event is a dictionary (which is common), you can print its keys and values\n",
    "    if isinstance(event, dict):\n",
    "        print(\"Event Keys:\", event.keys())\n",
    "        for key, value in event.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "    # Optionally, if event has specific known attributes, you can print them like this:\n",
    "    if 'messages' in event:\n",
    "        for message in event['messages']:\n",
    "            print(\"Message Content:\", message['content'])\n",
    "\n",
    "    # Print the last message or specific components\n",
    "    # if 'messages' in event:\n",
    "    #     event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ee499-8c62-4efb-abf5-e00e9b3a2008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7d96bfcc-f763-4e1b-84d3-7b1cfe161182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverallState(TypedDict):\n",
    "    query: str\n",
    "    tasks: List[str]\n",
    "    answers: Annotated[list, operator.add]\n",
    "    feedback: str\n",
    "    ans: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27429f1-505f-4a71-b5dc-1b137459a345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "452b671f-cc9e-4e89-ac11-4b36698180f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human Feedback\n",
    "def human_feedback(state: OverallState):\n",
    "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
    "    pass\n",
    "\n",
    "def should_continue(state: OverallState):\n",
    "    \"\"\" Return the next node to execute \"\"\"\n",
    "\n",
    "    user_feedback = input(\"Please provide feedback or 'Punch it!' Captain Pike! (I mean hit enter): \").strip()\n",
    "\n",
    "    # If no feedback is provided, use \"Punch It!\" as default\n",
    "    state.feedback = user_feedback if user_feedback else \"Punch It!\"\n",
    "\n",
    "    # Check if feedback is not \"Punch It!\" to proceed\n",
    "    if state.feedback != \"Punch It!\":\n",
    "        return \"plan_agent\"\n",
    "    \n",
    "    # Otherwise end\n",
    "    return \"combine_answers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106e384-431a-497e-9e84-4bdb223fbbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2a4d6a36-2915-4918-9b59-4cf371acdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_answers(state: OverallState) -> str:\n",
    "    \"\"\" Combine all the answers in the Dictionary & Generate a final comprehensive answer. \"\"\"\n",
    "    context = \" \".join([v for v in state.answers if v])\n",
    "    \n",
    "    messages: List[AIMessage | HumanMessage | SystemMessage] = [\n",
    "        SystemMessage(content=\"\"\"\n",
    "            You are an AI assistant. Your task is to provide a detailed, natural language answer \n",
    "            to the main query based on the given sub-answers.\n",
    "        \"\"\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "            Here is the main query: \"{state.query}\".\n",
    "            Below are some relevant sub-answers:\n",
    "            {context}\n",
    "            \n",
    "            Please provide a detailed, natural language answer to the main query based on the sub-answers.\n",
    "        \"\"\")\n",
    "    ]\n",
    "    # Get the LLM's response\n",
    "    llm_response = llm.invoke(messages)\n",
    "    \n",
    "    # Assuming llm() returns a string. If it returns a message object, you might need to extract the content.\n",
    "    if isinstance(llm_response, AIMessage):\n",
    "        final_answer = llm_response.content\n",
    "    else:\n",
    "        final_answer = llm_response\n",
    "    \n",
    "    # Store the final answer in the state\n",
    "    state.ans = final_answer\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "805bf246-6ed9-40ed-bee0-1c9929f93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize( state: OverallState):\n",
    "    return [Send(\"solve\", {\"task\": task,\n",
    "                             \"messages\": [HumanMessage(content=f\"solve the task {task}\")], \"innerloop.task\": task}) for task in state.tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8fb8e8f1-66ff-4173-9e59-ba12f7c0422d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCALSAOcDASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAUGBAcIAwIBCf/EAFgQAAAFAwEDBAsMBgYIBgMBAAABAgMEBQYREgcTIRYxVpQUFRciQVV0stHS0wg0NTZCUVR1kpOVsyMyN2FxgSRTcnORtBglM1JiobHUCUNEY4LwRmTB4f/EABsBAQACAwEBAAAAAAAAAAAAAAABAwIEBQYH/8QAOBEBAAECAQYLBwQDAQAAAAAAAAECEQMEEjFRYdETFBUhM0FTcZGhsQUyNFKBksFiotLwcsLhI//aAAwDAQACEQMRAD8A/qmAAAAAAAAAAAAAAAAAAAAMeXUItPSSpUlmMk+Y3nCQR/4iBdkzLsfeYgSnqbSWVG25PZJO9kqI8KS0aiMkoLiRrxkzyScY1D3i2DbsR03k0aI9JUeVSZTZPvKP97i8qP8AmY2MyinpJ59Ufn+ym2tlcqqJ44gdaR6Q5VUTxxA60j0j95LUXxRA6sj0ByWoviiB1ZHoD/x2+SeZ+cqqJ44gdaR6Q5VUTxxA60j0j95LUXxRA6sj0ByWoviiB1ZHoD/x2+RzPzlVRPHEDrSPSHKqieOIHWkekfvJai+KIHVkegOS1F8UQOrI9Af+O3yOZ+cqqJ44gdaR6RnRZsec3rjPtSEf7zSyUX+JDC5LUXxRA6sj0DCk2Bb8hZON0tiDJLOmVAT2O8kz8JLRg/m/wC2DPXMeE7kcywgK7DnTaBOYp9VeObEkHoiVNSSSs14/2T5JIkko/krSRErikySrTvLEKq6JoJiwAAMEAAAAAAAAAAAAAAAAAAAAAAAAIC+ag/TrakdiubmZJcahMO8f0bjziWkq/wDia9X8hPis7RE6LbKYeo0QJkWc5pTkybafQtw8fuQSjF+BETi0xOuExpT1Op8ekwI0KI0TEWM2lpptPMlCSwRf4EMgBT6/tksC1Ks/Sq3fFt0epx9O+hT6vHYeb1JJSdSFrJRZSojLJcSMj8IpmZmbyhcBrvaDtsptg3RAtxFCr1z1yVCcqRwaBES+4zFQtKFPL1LRw1KIiJOpRnzEPZXugdlyEoNW0m0EkstSTOuxS1FkyyX6T5yMv5DV23JJ7ZaZFn7N6HHvSpw2X2qZels3NGjuUacZJwhaiWRrbMjQpaCNWSwRoPJGIFpjbbK657oyqWFySqb9FjUuFKRPYbYLdLeW6SnnTU+R7kiQSCJKDXqQ5lJlpM5dnb5Tm75hW1VLYuegFUJzlNgVeq09LUGZIQS1bttZLNRaibWaTUlJKIuBnwFcYtu+7R23wbmOhJuuHWLcp9Gqs6FLZjnCksPuKcfNtw0mttRPKURIyrKcY4kNTU3YZfCK7Z9QqNgoqF1Ua7UVWsXnIq7Dj1Tjb1xOI6VK1IQltxCt0vdkkmsJJRmA3hT/AHQ8S4ajc8GgWfc9YXb0ybTpspmNHTHRJjoUrQS1vp1a9JEnTza069BHkZHubtq1Y2wbLaNcFboEujTpMVp5b7iGkRpZrIzNcckuuKJsub9JpVzcDH7sWsar2vTtoMesRewTq911SoxTJxDm8jPKLdud6Z4yRfqngy8JEKtsOuR/YlsvolpbTm6XYyaJHRTodWqNbiJjVY0aiNbJGslJ70kKMlkR9/zcAG+wGv8A/SE2WYz3S7Px8/b6L7QTFr7U7Lvie5Bty76DcE1to31xqXU2ZLiWyMiNZpQozJJGpJZ5sqL5wExX6O3XqNLgOnpJ5GErLnbWXFCy+Y0qIlEfzkQx7QrDlftel1B4iS+/HQp4k8xOYwsi/dqIxJypLcKM9IeUSGWkG4tR+BJFkz/wEFs8iuRLJo6XkKbecYJ9aFFg0KcM1mky+ctWP5DYjnwZvri3hN/SE9SxAADXQAAAAAAAAAAAAAAAAAAAAAAAA+HWkPtLadQlxtaTSpCyySiPnIy8JD7ABVaVOKziYo1UdJuCjSzT6g8vvXEcCS04o+Z0uYsn35YMjNWoisbkGM8s1uR2lrPnUpBGZj6kxmZkdxiQ0h9hxJpW24klJUR85GR8DIV3ufwo6v8AV8+q0lGc7mJNXui/g2vUlJfuSRENiZoxOeqbT5f88/oy5pT3a2J9FY+7L0D2aYbYTpabS2nOcISREKzyIf6U1779r2QciH+lNe+/a9kHB4fz+Ulo1rSAq3Ih/pTXvv2vZCqQ6bVX9qtXt5d01ntdFosKe2ZPNbzeuvykLye7/V0soxw59XE/A4PD+fyktGttQeb0dqQRE60hwi5iWkjwK1yIf6U1779r2QciH+lNe+/a9kHB4fz+Ulo1rB2tifRWPuy9A+24seMZrbZaaPHFSUkngK5yIf6U1779r2Q+k7Pqc8ZdspNQrSSz+iqMtbjJ559TRGSFf/JJ/wDMwzMKNNfhG+yLRrec19u/FdgRMO0FKy7Nl4PRKIuO4aPmWkzxrWWU4ygsqNW7tY+W20tIShCSQhJESUpLBEXzEPoV1151ojmiCZAABWgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABr6mmnu/3EWT1cmKZkvBjsuf+/8Aj4P8fBsEa+pue7/cX6uOTFM8BZ99T/5/48OfHhAbBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa9ppF/pA3GepJnyXpfe44l/S6hx/+/MY2ENeUzH+kFcfE88l6Xwx/wDt1DwgNhgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnSLvqtTccVQoEN6EhamylzpC298pJ6VGhCUHlGSMiUZlnGSI0mSjtw8KrE91MRdcQFI7eXh9BofWnvZh28vD6DQ+tPezF/Fa9ceMFl3AUjt5eH0Gh9ae9mHby8PoND6097MOK1648YLLuOArY93rV6z7ol+kR9lT5XHUm4tudrnKySdy8zIkKUta+x86S355yXAkGfhMdjdvLw+g0PrT3sxqGje5/eofuhartcYgUbt1Oibgom/dJpl4y0uSEmTeda0FpP+Kj8PBxWvXHjBZ0qApHby8PoND6097MO3l4fQaH1p72YcVr1x4wWXcBSO3l4fQaH1p72YdvLw+g0PrT3sw4rXrjxgsu4CkdvLw+g0PrT3sxlwLsqMWZHYrkGNHbkuEy1LhPqcQTh4JKVkpCTTqM8EeTIzwR4MyzE5NiRF4tP1gstgAA1EAAAAAAAAAAAAAAAAAAAAAAAANdbOT1WDbxnznAZM/wCJoLI2KNc7N/2f259XseYQ6GT9FX3x6VJ6ljABq5j3TezR65XqEdzFHqDU9dLUcuFJYY7KQs0KaJ9bZNGrURlwVx8GRlMxGlDaICHoV3Um5Z1ah02X2TIo0vsGcjdrRuX92hzRlRESu9cQeU5Ljz5IxMAAAI2LclMm3BPobE1p2rQGGZMmKk++abdNZNqPwd8bS+HPw485ZkSQAAAADBRXKe7WnqQiawuqMsJkuQ0uEbqGlKUlK1J5ySZpURGfPpP5gGcK/fJ6aC2Zc5T4Jl+4+y2uIsAr99fACPL4P+aaF2D0tPfDKnTDYYAA4zEAAAAAAAAAAAAAAAAAAAAAAABrnZv+z+3Pq9jzCGxhrnZv+z+3Pq9jzCHQyfoq++PSpPUsY40tmxr52vWXtDsaFColPs6pXtVeza5KluLmIQmoGtaWo5N6deUkRKNeOOeBjssQ1r2fSLMjTo9GidhszZz9RkJ3q165DyzW6vvjPGpRmeCwReAiEzF0NAxbnh2hR/dBT5r9UYb5Utx0HRXEomm69EhNNJaUrglSlrSRKPgWc+AU964b5sSgbarfqNQq0BcKzUVynJlXC5VJcF1RSEGpEo0IWkzNtJ6cqJJpylWDHSdY2M2XXp9xTJ9BYkP3DHbjVUzccSmUhvG7NSSUSdadKcLIiUWksHwIRcT3Ouz6ExVWm6Cs+21OcpVQddqElx2XGWZGpDrinDUs+BESzM1JLJJMiMyGE0yKPRH52zra3ZLL101mqUu5LdqE2qJrU9T7SHo5Rlk+2k+9Z4PLI0tklGMd7wGsNmO1KnHtYtm/FIqrEy+KlMp9S7LpMtlhEV7QVK0vuNE0vCY7SS0qPJyVmWeI6hujZRa15JilV6aqT2LT5NKZNEp5o0RZCUIebyhZGepLaCyfEscDLJ5yq7s6t25LRj2xUKcTtDj9j7mK2640bW4UlTJpWhRKSaTQnBkfgwfAzE5sjl236zcN1XnbyFXFdb9/NXo43cNvIkSG6ZDpjTzik94nDSWyaTHUlWcuGvB6yUZF7UU9rm15u4rot6eqDU49bmQoO9up2NFglHfNtLL1OTEW253qSNWtZqVryRpyRFbG/c7XeztERVKdIpFsU9NbOprn0itVU3nWTfN1bJwnHDjEbhGaVmWU98oySXMNqVDYHYVTu5dzP0BJVhyQ3LdcZlPtNPPoMjQ64yhZNrWRkR6lJM8lzjGKZkaHuyVcTtobdLvReFww6raNbfOkxo1ScTDYJqLGeNBtfquIUa1EaV5SRfqkkzMzuVCtOJWPdc16quT6uw+Vs0qopYYqshtlSjekJNCm0rJKmy0Ee7MjTqNR4yozPbUrZVa02i3VSXqXrp90PuSKuz2Q6XZLi20NrPJKyjKG0FhBpLhnnMx8V3ZLalx3JR7gnUtSqzSEIbiTGJTzC0oSslpQvdrSTiCUWrSvUWc8OJjLNkW8V++vgBHl8H/NNCwCv318AI8vg/5pobWD0tPfDKnTDYYAA4zEAAAAAAAAAAAAAAAAAAAAAAABrnZv+z+3Pq9jzCGxhQWqXWbSZ7AiUlytU9rJRXIz7aHEN54IWTikllPEskfEiLgRjfyeYmiqi9pmYnn5tF9femE2AhO21f6G1PrUP24/Dq9eSRmdm1MiLiZnKh+3Gxwf6o+6nemycAV2HcVcnNLcbsqsoSlxbWHnYrRmaFGkzIlPEZpyk8K5lFhSTNJkZ+/bav8AQ2p9ah+3Dg/1R91O8smwEJ22r/Q2p9ah+3DttX+htT61D9uHB/qj7qd5ZNgITttX+htT61D9uHbav9Dan1qH7cOD/VH3U7yybAav2q7eoGxOhxazeVAq1IpkmSURuSW5fTvTSaiSe6cUZcEq5/mH3s729UfazFN+0Yiq7hG8WzGqELfNpyRZW0b5LSWTIsmRc4cH+qPup3lmzRX76+AEeXwf800PXttX+htT61D9uPVmlVa5pEVufTVUemsPtyXUvPoW88ptRLQgibUpJJ1pI1GauJJ0474zTlTbDqiuqYtHPpifSSItN15AAHGYgAAAAAAAAAAAAAAAAAAAAAAAAAACtrZK9iWh5slW2pDjL0SVGcaclOpdIs98af0P6NZYNKkvJcI/1Mbz8kqbvOQ9CbWxJoDKzRJfizVE4uS06WpgyRjvCNJk4Rq48W1JMjUQsoAAAAAAAAAADVHupNkrm2zYbc9rxWUPVV1gpFOJRkn+ktnrQRGoyIjVg0ZMyItZ8S5xQ/cx+5movuTqGUiciJUK3PiGdYulR6UxTJSDKM3qLKY/Oo18Mm3qWRFoJHSY832GpTDjLzaHmXEmhbbiSUlSTLBkZHzkZeAB6AIRLsqh1A23jkToEyQtaZClNkmARpThtWTJSkmslYMtRkayI8JIjKbAAAAAAAAAAAAAAAAAAAAAAAAAAAAEHdU18ozVLgS3oFUqWtmNMailI7Gwg1KdNJ96Wki4GrJajSWFZ0nOCvUhS6hdtdln23Ybhk1TkMSyJEN0yQTyn2C5153yW1LPhlg0pIsKNQTkaM1DYQyy2lptBcEoSSSL+RcB6gAAAAAAAAAAAAAAA8J8CNVIMiFNjtS4cltTL0d9BLbdQosKSpJ8DIyMyMj4GRiGtyonHqE6gS5kN2dDJL7DEclpWUJalJZNZKM8qI21oNRGZGaM97q0lYBW69MTTLstlxypsQ25zj9OTEcja1zHTaU+gkuFxRpTHeVg+Ciz4SSAsgAAAAAAAAAAD4ddQw0txxRIbQRqUpR4IiLnMxAFtFtcyyVw03HlSPSKa8bDwukqiO+bJiJnQsQCu90S1+kFN60j0h3RLX6QU3rSPSK+N5P2lPjCc2dSxAK73RLX6QU3rSPSHdEtfpBTetI9IcbyftKfGDNnUsQCu90S1+kFN60j0h3RLX6QU3rSPSHG8n7SnxgzZ1LEArvdEtfpBTetI9Id0S1+kFN60j0hxvJ+0p8YM2dSxCuWIaHaNJkITV2ykVCY4bdb4PpPshxOEl8lrvctl/VmjwmY/e6Ja/SCm9aR6RXrA2iWzyVja7hdNW9fz28lI7L/ANsv9bm73/d/4NIcbyftKfGDNnU2GArvdEtfpBTetI9Id0S1+kFN60j0hxvJ+0p8YM2dSxAK73RLX6QU3rSPSHdEtfpBTetI9IcbyftKfGDNnUsQCu90S1+kFN60j0h3RLX6QU3rSPSHG8n7SnxgzZ1LEArvdEtfpBTetI9Id0S1+kFN60j0hxvJ+0p8YM2dSxAK73RLX6QU3rSPSJal1iDXIxyKfMYmsEo0G4w4S0koucsl4eJDOjHwsSc2iuJnZMItMaWYK5edSOl9onO26KSh2qsMK1xt92Vr1JJguHeGozLv/Bj94sYrt7VPtVEpS+26KPvqpEj7xcbf7/W6lO4Ivkm5nTr+TnIvQsQAAAAAAAAAI64/i9VPJXfMMYtvfAFM8la8whlXH8Xqp5K75hjFt74ApnkrXmEOBl/T0935W0aEgAANFmAAAAAAAIGhX9bF0PTmaNcdJqzsAzKW3BnNPKjmXPvCSo9HMfPgStUaYfpktuUaijLZWl00mZHoNJ6sY482ebiOEI8lM3ZVfuz3Z8uPe9vwbdjyI9epVMVFqKIyZiN9TJRkkt68pjfGWCSo++1JyeRdh4efdEzZ2BU9sFtnY91XFbtYpV1lb8CRMfj0yotO9802pe7UpBq0GrQZZMjx8x4GNsZvWBctmUNKpkpuszIJ1RVMrEpLlQQw46vS4ouCjazlKF6SI0kn+A57uyXbe0+7pzuyKGzMp8WwK3T6u9SIZtMrN1tsoUQ8JIjdJaXDJv8AWSRnwIebdTqFK2HbKtqdgxajWazTIT1tvxZp5kPJkqNhCF5+S1OQxpSfMjJCzgotbrlF3U0/aTaNKo51abdNFh0opC4hzpFRZQwT6VGlbWs1adZKSojTnJGRljgJun1CLVoTEyDJZmQ30E41IjuE424k+ZSVFwMv3kON742fwdj9/wCz2DcN0TLXsynWounxrhTT40tjtqcjeSjdOSw8hpb6TJZLwk1GlSc85Dob3PdrUK1dm7CLbrM2uUWfLkVBiVNjojcXXDNZNtIaaS23r1GlKUEXfZLgZCuvDimnOiUxLZQAApSAAAAAAAIez/fNxfWavyWhMCHs/wB83F9Zq/JaF+S/EUfX0RV7srGK9etT7VRKWs6smj76qRI+8VH32/1vJTuMYPSbmdOv5Oc5IWEV29qiqmw6WtNYRRd7VIbBuLj77fkt5KdwRY703M6Nfyc58A9MoWIAAAAAAAAAEdcfxeqnkrvmGMW3vgCmeSteYQyrj+L1U8ld8wxi298AUzyVrzCHAy/p6e78raNCQAAGizA5gFIqsZi67oqNPqTSZdOp7bOmG6WppxxZKUa1pMsKwWkiI8kXE8Z4jdyTJpyrEzL2iIvM/wB7zRzrl2Wx/XN/bIOy2P65v7ZCm9z61ujdI6g16odz61ujdI6g16o7XJGD2k/bH8mOdC5dlsf1zf2yDstj+ub+2Qpvc+tbo3SOoNeqHc+tbo3SOoNeqHJGD2k/bH8jOhU/dWbKWtt2xSuUCM8kquwRT6aaXMH2S2StKef5STWj/wCY53/8MzY7ItyiVzaFXFOMTajqpUBl9ZkaWELI3l4P/ecQlJf3SvnHWnc+tbo3SOoNeqHc+tbo3SOoNeqL49nYdOHOHwk2n9MfyY3i91y7LY/rm/tkHZbH9c39shTe59a3RukdQa9UO59a3RukdQa9UUckYPaT9sfyZZ0Ll2Wx/XN/bIOy2P65v7ZCm9z61ujdI6g16odz61ujdI6g16ockYPaT9sfyM6F1Q4lxOUKJRfOk8j6Gua5RadZtNerVGgxqVKhkTijhtJaS82R982sklhSTIz5+Y8GWDLI2MOVluRcUzZpqvE36raLX651wmJvzgAA5qQQ9n++bi+s1fktCYEPZ/vm4vrNX5LQvyX4ij6+iKvdlYxXb2qHa6HS19t0Ube1SGzvFxt/v9TyU7gi+SbmdBL+TnPgFiFcvioppsKlrVVkUje1WGwTi4vZG+NbyU7gi+SbmdJL+TnPgHplCxgAAAAAAAAAjrj+L1U8ld8wxi298AUzyVrzCGVcfxeqnkrvmGMW3vgCmeSteYQ4GX9PT3flbRoSAAA0WYKXA+PN0fwi/lmLoKXA+PN0fwi/lmO77I6XE/x/2pRVolOAAom0bawjZw6ne2nc1ejJjqlSJdEgpeZjNpM8mtSnE5MiIz0pJSsccD0UzZQvYDV9Z90HQYVRosGkUmuXbIqtJRXWk0GGl424K1ElD6yWtB4UZ4JKdSuB96M2Ltpp9Sv6oWtTaBX6oqnSUwptWiREKgxnzaJzdrWayVnSpOTJJpI1EWRF4GwwGibX90RGiWuufUo1x1qqVG551HgUIqbGantONGo1RtKHjbUlpKFEbinCNWMmMm8tvVbod/7PKVT7JrsyBcMGZMkxex2ETUqbJGlsicfQSVI1Gpwj8CkaTPviJnQN2gNa3tt0p+z+uOxKvbdytUhh1lmRcaICVU1g3TSSTU5r1mkjWkjUlBkR5Iz4GMa7PdB0m1a/ctITblx1l+3GWpVUdpcNtxqOw43vCcNSnE5IkkrvSyvvTwkyLIXgbTAaXqm3moI2yWxb1HtyoV+26xQFVdE2A2zqXqdYSh0jceRhpCHD1lp1ZWnSSuON0CYm4rm0b4jVvyZQvYom0b4jVvyZQvY43tfosLvq/wBV1OgAAHmWQIez/fNxfWavyWhMCHs/3zcX1mr8loX5L8RR9fRFXuysYrt7VLtXDpa+3RUTe1SGxvTi9kdka3kp7Hxjvd5nRr+Tqz4BYhXb1qJ02HS1lWEUXe1SGxvFxt/v9byU7gi+SbmdGv5Oc+AemULEAAAAAAAAACOuP4vVTyV3zDGLb3wBTPJWvMIZVx/F6qeSu+YYxbe+AKZ5K15hDgZf09Pd+VtGhIAADRZgpcD483R/CL+WYugpcD483R/CL+WY7vsjpcT/AB/2pRVolODnzbRsyuG79o0qTItJu+7ekUZMOlx5NRbYi0mZrc3j7zSz7/USmsOIStadBkSR0GA9FMXUOT6zsuvgtk9hUanWDIYvmh0BqBDuiDXo8V2lykfozJzCsux1EhKzSWslErBoJXErZWrHvOTtlolYotrLoExqdF7dXXFqzSYlYgoaInm3oZHqU4Z5SgzQZpwk9ZFwLoQBjmwOb3tmNZjWNcdNquzxy7TnXtVKvHYi1diHKisuvOLYlsOmstK+JcNaFESjz/un9x7L2nUGDsguSo007zuS3GKjFq0NFQZRIU3JSkmlb1w0ocU2lttKzyWo8mWR0aAZsDkPbBsSvW/T2gtyLHbuSt1V1EihV6dVmUs0yMltoyiNtqUam3CWh1OpKSSs3MqWRDa0axbhfunbLUnKUqOxctJgs05Lj7RqddRDdbcQelZ6TStaU5PBHzkZlxG5gDNjSOdqPY172BL2S16Fa6rgkUizSturUtmewy9FdNMVWslLUSFpJTCknpUfORlkdEgAmIsK5tG+I1b8mUL2KJtG+I1b8mUL2OP7X6LC76v9V1OgAAHmWQIez/fNxfWavyWhMCHs/wB83F9Zq/JaF+S/EUfX0RV7srGK7e0/tfDpau2rNJ3lUhs7x6Pvie1PJLckXyVLzpJfyTPPgFiFdvaf2vh0tXbVqk7yqQ2d49H3xPankluSL5Kl50kv5JnnwD0yhYgAAAAAAAAAR1x/F6qeSu+YYxbe+AKZ5K15hDKuP4vVTyV3zDGLb3wBTPJWvMIcDL+np7vyto0JAAAaLMFMjp7GvuvIcPSuSzGfaIz/AF0ElSFGXz4MuPzZL5xcxHVq34FwMttzmTc3atTbjbimnGzxjKVoMlJ4cOBkOhkOU05LiTVXHNMWm3fE/hE88WeACN7mtH+k1v8AHp3tg7mtH+k1v8ene2Hf5SyPXV9sfyY5m1JAI3ua0f6TW/x6d7YO5rR/pNb/AB6d7YOUsj11fbH8jM2pIBG9zWj/AEmt/j072wp+yS0o9y2FBqNUqFbkzXXpSVu9upiMkiQ4hPAnSLglKS5vAJ5SyS171fbH8kZm1sIBG9zWj/Sa3+PTvbB3NaP9Jrf49O9sI5SyPXV9sfyTmbUkAje5rR/pNb/Hp3tg7mtH+k1v8ene2DlLI9dX2x/IzNqP2gET1pT4pH+mlkUZlBc63FqJKSIvCfH/AJGL0IOk2ZSqNLTKZbkvyUJNKHpsx6UpBHz6TdWrTnOOGOAnBx/aGWUZTm04cTam+nbbbOrWyiLRYAAHISCHs/3zcX1mr8loTAh7P983F9Zq/JaF+S/EUfX0RV7srGK7e0/tfDpau2rVJ3lUhs7x6Pvie1PJLckXyVLzpJfyTPPgFiFdvaf2vh0tXbVqk7yqQ2d49H3xPankluSL5Kl50kv5JnnwD0yhYgAAAAAAAAAR1x/F6qeSu+YYxbe+AKZ5K15hDKuP4vVTyV3zDGLb3wBTPJWvMIcDL+np7vyto0JAAAaLMAAAAAAAAAAGv9gx52XUzmL+kTebH0t75hsAa+2CGR7LaYZZx2RN5zz/AOreGUe7P91o62wQABikAAAAAAAAAAEPZ/vm4vrNX5LQmBD2f75uL6zV+S0L8l+Io+voir3ZWMV29p/a+HS1dtWqTvKpDZ3j0ffE9qeSW5IvkqXnSS/kmefALEK7e0/tfDpau2rVJ3lUhs7x6Pvie1PJLckXyVLzpJfyTPPgHplCxAAAAAAAAAAjrj+L1U8ld8wxi298AUzyVrzCGVcfxeqnkrvmGMW3vgCmeSteYQ4GX9PT3flbRoSAAA0WYAAAAAAAAAANfbBFatltMPUav6RN4q5/fbw2CNf7BzM9l1MyZn/SJvOrV/6t7wjKPdn+60dbYAAAxSAAAAAAAAAACHs/3zcX1mr8loTAh7P983F9Zq/JaF+S/EUfX0RV7srGK7etQ7XQ6WvtozSt7VIjOt6Pvie1vJTuSL5Kl50kv5JnnwCxCu3tP7Xw6Wrtq1Sd5VIbO8ej74ntTyS3JF8lS86SX8kzz4B6ZQsQAAAAAAAAAI64/i9VPJXfMMYtvfAFM8la8whlXH8Xqp5K75hjFt74ApnkrXmEOBl/T0935W0aEgAANFmAAAACmpuCuXClUmiuU+DTjM0sPTY65C3yI8bwkocQSUnxxkzMywZ4zgvzN5+OaF+Dvf8AdDs0+yseYvVMROqb/iJReI61zAUzN5+OaF+Dvf8AdBm8/HNC/B3v+6E8k43zU+e4vGtH7fNp9T2N7Mqnd9MtvlV2tNDkmCUw4qksGeFOErduZ0maTMsc2TzwGlfcJ+6IqW2eiVOjlZ50ik0TeLVVzqO+3rzz63Esk3uk4wlSsq1H+qXDvuG8anTrprNNl0+dUrfkwpbS2H2HKM8aXG1EaVJP+l8xkZkKbsX2MT9g9lptm2atSuweyHJTj0ulOredcWfE1GmSkuBElJYIuCS/iL49l1xhzTM03753IvF9LdwCmZvPxzQvwd7/ALoM3n45oX4O9/3Qo5Jxvmp89ybxrXMBTM3n45oX4O9/3Q+0SLvjka1zaJPNPHcJgvRtf7t5vnNOeHHSePmMJ9k43VVT4zuLxrXABgUOsM1+lsTmErbQ5qSptzGttaVGlaFYMy1JUlSTwZlkjwZlxGeOPXTVRVNFUWmEgAAxAQ9n++bi+s1fktCYEPZ/vm4vrNX5LQvyX4ij6+iKvdlYxXb2n9r4dLV21apO8qkNnePR98T2p5Jbki+SpedJL+SZ58AsQrt7T+18Olq7atUneVSGzvHo++J7U8ktyRfJUvOkl/JM8+AemULEAAAAAAAAACOuP4vVTyV3zDGLb3wBTPJWvMIZVx/F6qeSu+YYxbe+AKZ5K15hDgZf09Pd+VtGhIAADRZgAACibOFGvZ/balGalHTo5mZ85/o0ixit7Nv2e219XR/y0iyD6NjdLV3z6qJ0yANW0/3TuzSp3KmgtXLuqiqaumoKVAksMrkpWaDaS842ltStRGRESjyfNkbSFETE6EACs1raTbtv3XTbamT19vaiklsQo8Z19ZINWgnHN2hRNINWS1rNKckfHgYzrRu6k33bkKu0OX2dSpiVKYkbtbesiUaT71ZEouKTLiXgC4mAAYNZrlPt6D2ZVJrFPi7xDW+kOEhOtaiQhOT8KlKSki8JmRCRnAAAI7Zwo1UGYZmZn21qBcfK3RaRVdm3wBM+tqj/AJt0WoeO9ofF4v8AlPq2AAAaACHs/wB83F9Zq/JaEwIez/fNxfWavyWhfkvxFH19EVe7Kxiu3tP7Xw6Wrtq1Sd5VIbO8ej74ntTyS3JF8lS86SX8kzz4BYhXb2n9r4dLV21apO8qkNnePR98T2p5Jbki+SpedJL+SZ58A9MoWIAAAAAAAAAEdcfxeqnkrvmGMW3vgCmeSteYQyrj+L1U8ld8wxi298AUzyVrzCHAy/p6e78raNCQAAGizAAAFD2bfs9tr6uj/lpFkFb2bfs9tr6uj/lpFkH0bH6Wrvn1UTplwnAl16vWfHsip0+BSbEr+0Gcw5dByVOPNOt1Jb6Gd1oImlOLb3aXDUouPEiMyFwjHtX2v1K96zb09yDOplem0mnK5VOw48DsdzS2l6AmItt7JES1bxZmol8DQWMdFu7ILQfsuqWk5RkOW/U33pUqGt509brrpurWSzVqSe8PURpMtJ404wQi6l7nuwKvcZV2VQTXVDNpTryZshCZKmsbtb6EuEl5RYLvnCUfDiY1MyUKBY1n6fdZXdU5lQqnZ7Fv0yS5HRU31RTcdVLQtG7NWlTaTIzQgywkzNRERmY1pbNz3JG2E7DrTt11UU7llzmJL7dSVTlqSyb7hMJlJacNpS1FzpTqPQaSNOrJdbxbRpMK6qhcbMTRWp8ZmHJk7xZ7xpo1qbTpM9JYNxfEiIzzxM8EKw7sEsF+2Z9vLtxjtNNqCqq5EJ10ktyjxl1kyVllXD/yzTjJ45zzObPUNI1VvahY0WlWzWa87RaNdVzwaXEnt1pdUnwGFMvLkNFLdYbPU4pptLalEo07xXHgkTPuidl0S3dixQzuK56ixykpLxOVGtvuut6pjLRpJzUSjSRKNREoz0rwosGlONss7DLGZsudaiqC3JoU5/smSxLkOyFuvYSROm64tTmstCcK1ZLSWDLA/IOwux6faNXtlNEORRauaTnMTJb8lb5pxpM3HFqXlOlODJRGRkRlgyDNkWygUVq3aPFprEiZKajp0peqEpyU+riZ5W64ZqUfHnMzEgIm1bWp1l0KNR6S281Aj6t2iRJdkLLUo1Hlx1Slq4mfOZiWGYjdm3wBM+tqj/m3RahVdm3wBM+tqj/m3Rah4/2h8Xi/5T6tgAAGgAh7P983F9Zq/JaEwIez/fNxfWavyWhfkvxFH19EVe7Kxiu3tP7Xw6WrtqzSd5VIbO8ej74ntTyS3JF8lS86SX8kzz4BYhXb2mnBh0tRVKNTN5VIbWuSzvSd1PJLdJLwKXnSSvAZkY9MoWIAAAAAAAAAEdcfxeqnkrvmGMW3vgCmeSteYQyrj+L1U8ld8wxi298AUzyVrzCHAy/p6e78raNCQAAGizAAAFE2cJNOz62yURkZU6ORkfg/RpFjEIiiVu2mzh0mLCqVNSZnHQ/JVHdYSZ5Jvg2olpLJkSuB40kZKMjUf5v7t6PU78WV7Ae9qynBxpnEpri08/PMR5SrmmZlOAIPf3b0ep34sr2Ab+7ej1O/FlewGPC4Xz0/dG9GZKcAQe/u3o9TvxZXsBEWnd9w3lQmKtAt2GmK8t1tJPVQ0qy24ptWSJk/Cg/5CeFwvnp+6N5mSuYCD3929Hqd+LK9gG/u3o9TvxZXsBHC4Xz0/dG8zJTgCD3929Hqd+LK9gPtHK2RlvtTS4Rq4b9yoLeJH79BNJNWOHe6k548SCcbBjnnEp8Y3mZLI2cJNNBmEZGR9tagfHyt0WkYFCozVApbMJlanCQalrdXjU44tRrWs8ERZUpSlHgiLiM8eOyrEpxsoxMSnRMzPmtAABqgIez/AHzcX1mr8loTAh7P983F9Zq/JaF+S/EUfX0RV7srGK7e8zsKHS1dsItO3lUhta5bG9J3U8kt0kvAtedKVeAzIxYhXb3mphQ6WpVTYpe8qsNolyI++J01PJLcpL5Kl50kv5JnnwD0yhYgAAAAAAAAAR1x/F6qeSu+YYxbe+AKZ5K15hDKuP4vVTyV3zDGLb3wBTPJWvMIcDL+np7vyto0JAAAaLMAAAAAAAAAAGv9gx52XUzBGX9Im8/lbw2ANf7BiMtl1MIyMv6RN506f/VveAZR7s/3WjrbAAAGKQAAAAAAAAAAQ9n++bi+s1fktCYEPZ/vm4vrNX5LQvyX4ij6+iKvdlYxXL3ndgQ6WrtlHpm8qsNnXIj74ndTyS3SS+SpedJK+SZ58AsYrt6zlQIdLUmpR6ZvKpDZNclnek6Snklukl4FLzpJXgMyMemULEAAAAAAAAADCrbDkqjT2Wk63XI7iEJ+czSZEQrVJrc+FSocdy2qvvGWUNq0kxjJJIj/APNFyAc/KMjjKKorzpiY5ua35hnFVlX5SzOjVY+yx7UOUszo1WPsse1FoAa3JsdpPluTn7FX5SzOjVY+yx7UOUszo1WPsse1FoAOTY7SfLcZ+xV+Uszo1WPsse1DlLM6NVj7LHtRaADk2O0ny3GfsVflLM6NVj7LHtQ5SzOjVY+yx7UWgA5NjtJ8txn7FX5SzOjVY+yx7UUHYXcMlrZjTUot6qOpKRM79omtJ/0t753SP/8A0bmGu/c/8NltPT/uTKgg/wCJTnyP/oMuTotbhJ8txn7E5ylmdGqx9lj2ocpZnRqsfZY9qLQAx5NjtJ8txn7FX5SzOjVY+yx7UOUszo1WPsse1FoAOTY7SfLcZ+xV+Uszo1WPsse1DlLM6NVj7LHtRaADk2O0ny3GfsVflLM6NVj7LHtQ5SzOjVY+yx7UWgA5NjtJ8txn7FX5SzOjVY+yx7Ue1mMykoq8iVDegnKnqebaf069G7bTk9JmXOk/CLEAuwchjBxIxM+Zt3fiETVeLArt7TDhQ6WpNTj0s3KpDa1yWd6T2p5JblJeBS/1SV4DPIsQrl6zOxGqMkqmxS1P1WM0Rvx99v8Av8myksd6pREZEr5POOmwWMAAAAAAAAAAAAAAAAAAAAAAAAAABrzYUlTFkToi0mlcW4a2xgyx3pVSUaD/AJoNJ/zGwxrzZuSaNe+0SgKMyWVSarTDZljEeUwktRceOZEeX/gA2GAAAAAAAAAAAAAAAAArl0Tt3W7WhIqjMB6TPWrsdyPvVTG0R3VKbSeP0Zkehev5kmnnULGK81NOo3y6zHqpGxS4ZomUwoucvPKQppw3j5jShpwtCfA7lXyAFhAAAAAAAAAAAAAAAAAAAAAAAAAAAa92ho5IXFSb8RqTDhNKp9bJCc/0FxRKJ8/3MOESzPwNrfMbCHw8y3JZcZebS604k0LbWRGlRHwMjI+cgH2AoVmOuWNW02TLMzpxtret+So1K1R041xFqPP6RnUWnJ5U1pPvjbcULrCqEWpsqehyWZbSXXGVOMOEtJONrUhxBmXykrSpJlzkaTI+JAMgAAAAAAAAAAAABi1SoN0imy5zyHnGozS3lojtKdcUSSMzJCEkalKPHBJEZmfAhh2zGlR6WTk2VJlSJLrkkylIQhbKVqNSWdKckRNpMkc5505MzMzMYkxDlfuBuKbUhum01Tco5kealCH5GVl2OpCD1mSC0uKJWlJmpvGvvyTYQAAAAAAAAAAAAAAAAAAAAAAFb2gz36fbKzjvLjuyJUWHvWzwpCXpDbSjSfgPSs8GXEj4izDonEriiOubJjnZk28qBTX1MTK5TYryTwpt+W2hRH8xkZ5GP3QrW6S0fr7XrCPiUOnwI6GI8GOy0giJKUtlgeva+L9GZ+7IbvA4O3yOZl90K1uktH6+16wd0K1uktH6+16wxO18X6Mz92Qdr4v0Zn7sg4LB2+Mbk8znX3cLF2bTtnZUrZ9dlqO08jJ2bBVKabqLhkSiMmX1OaCSpKzJSSShZkRp1qS4pAwv/Dsulq1tg0mgXTKaoVQp1YkIbj1N1LCjaUltZGklmWS1KXxLgOl+18X6Mz92Qdr4v0Zn7sg4LB2+MbjmZfdCtbpLR+vtesHdCtbpLR+vtesMTtfF+jM/dkHa+L9GZ+7IOCwdvjG45mX3QrW6S0fr7XrB3QrW6S0fr7XrDE7XxfozP3ZB2vi/RmfuyDgsHb4xuOZl90K1uktH6+16wd0K1uktH6+16wxO18X6Mz92Qdr4v0Zn7sg4LB2+MbjmZfdCtbpLR+vtesIuvbULfYZbiU+56IipysojuPvk6y2ZFlSnNB8CIs4JSkko8J1EZkMntfF+jM/dkHa+L9GZ+7IOCwdvjG45n5SbqsmhQiiQK5Q4sfeOOmhua0WpxxanHFn33FSlqUpSj4mpRmfExmd0K1uktH6+16wxO18X6Mz92Qdr4v0Zn7sg4LB2+MbjmZfdCtbpLR+vtesHdCtbpLR+vtesMTtfF+jM/dkHa+L9GZ+7IOCwdvjG45krTrsodYkExArNPnPnkyajSkOKPHPwIzMSwpk636dUmDafhtKLJGlSUklaFEeSUlRcUqIyIyUWDIyIyErYlVkVuzqRNlL3sl2OneuYxrUXA1YLmyZZx+8U4uDTTTn0aNHP/diNsJ4AAaiAAAAAAAAAAAVLaf8AFmN9bU3/ADrItoqW0/4sxvram/51kbOTdPR3x6pjTDKAAG0gAU3bHfUrZpsvuW54VMfq0qmQXpLcdkkng0oM9a9Sk/o041KwerSR4IzwR0CxtrlRtrZ9bkm6G7mum7Lh1yYtFbpkRubu0pTvDQhlZNJYTklEtxzVh1JGeTwMbxE2G8QGsEe6Ftx23E1FuDWXaoqpKo5W4mF/rM5qUbxTO61ack3+kNWrRp46sD5T7oq2I9t12qVSLV6JMor7MWXRJ8PFQ3z2Ox2220KUThumeEGhRkeD4lg8LwNogOVL+90Nd5p2rSKZGq9o9orRi1GDArcCOl9iUt94lPFjeEtKkpQWDUpJGkywRkY3HaG3GmXNdB23LoletutqiKnRY1chEwc9lOCWtg0rUSjTqTlB6Vlksp58RFUSNkANa2pt3pdxXM3Qqhb9w2jOkRHZsPlHCTGRLZaNO9UgyWrBpJaTNK9KiI84Hja+3aHfpmdDtu5e1Ehl5cK5H6elFPfJCVGS0qNesknp71SkESuGDPIm8DaADTGwnbYq87ZsOlVFUquXZUqA1V6pListJZhpUXerfwaSQbitRIQhJmekzwSSyNziYm/PAANQ237pm37lcoDrdCuKDSK5NOmQ6zNhtoiKl5WkmTMnDXk1IUklEk0GZY1ZHrUPdK2zTqvNaVTa47QoNRKkzLoahpOmRpWsmzQtzWS8JWokGskGglHg1CM6BtkBofbl7oxNrW1f0G1adXKjWqDTnt/WqbAbfhUuUbJrbJ1S1YUacoUokpWSSPvscRZ5u3GNRewqa1Qq/d1abp0ebUW7fhIe7ES4jKVOmpaEkpelRkhOVGRZ04wGdA2iAibTuqmXxbVNr1GklLpdQZS/He0mk1JP5yPiRlzGR8SMjIxLCQHhst/Z/Rf7k/OMe48Nlv7P6L/cn5xhi9BPfHpKepagABzUAAAAAAAAAAAqW0/4sxvram/51kW0VLaf8WY31tTf86yNnJuno749UxphlAADaQp22WgT7r2Q3xRKUx2VU6lQ50OKxrSjeOuMLQhOpRkksqMiyZkReExqTabsVqNUqGzq412ZT79RRaQqk1O2ag4wSjJaWjJ5lTv6LWhbZkeTLKVcDHRgDGYuOYrw2BHWLas2s0rZRb8B+jVWTMnWGp2NuJzLrZsmo3CSTW/JKWllnvSNONR4LOZVNjs6XYsWqWpswo9iXHSbjhVtmgtyI6TqbcbOEPOskaEKMnXiTxUSTJJ5LJ46RARmwOWb82ebQtqitqM56zF289XrSiUanxZVTjPKW+iQ+tZKU2syTgnCPnMsY45ykrRUrX2h7UL2pdclW+iwV21SKkxTXpFQZmOyJ0plLSFkTWSS03p1ZVhSjMu9LA38AZo5CtbYFcMm4bPefsA7a3VKqNJuCuO1ZiXOmvyYu7OWoyWZuIJaTPvla/0v6hERjaeyhe0O37Uodi1uxW48ak03tY5cMarMKjPoaYNDTjbX+1ys0oylSUknUZ5PGD3UARTbQOXNiGyOse5wpNoVpxnsODOpSIl7s1CptaITzaVKZmE4tzRpbyplSUKxoNBkR6TG7oW2/ZzUpjESJf8Aa8qXIcS0ywzWYy1uLUeEpSkl5MzMyIiLnyLotCXEmlSSUk+BkZZIx4pgRkqJSY7RGR5IyQXATEW5oHPFF2SXZE2IbMqA7StFXo13RapOj9ktHuYyKi48peol6VYbUSsJMz44xngImr7KL/7nVybIYduMu0Or1aQ61dp1BommIUiWchetgz3qnkkpaCIk6TPSeoiHUgCM2By/d9gbRKDbG2GzKJZybmpt4vz6hT6w1VI8fcrlMklbLzbqiVqSoj0qTkjI0kZp448q5sMnUjaJU7gm7LKTtRhVynQEbqU/FbkUuTHjkypGX+9U0skoPKDMyMj70+A6lAM2BD2fRY1u2vTKfDpESgsMsJ/1ZBItxGUffKQjBERkSjPiRFnnxxEwADIB4bLf2f0X+5PzjHuPDZb+z+i/3J+cYYvQT3x6SnqWoAAc1AAAAAAAAAAAKltP+LMb62pv+dZFtFS2n/FmN9bU3/OsjZybp6O+PVMaYZQxajCXPYJpEp6GZKJRuMGRKMi8HEj4DKAbKENyde8c1H7aPVDk6945qP20eqJkBGbAhuTr3jmo/bR6ocnXvHNR+2j1RMgGbAhuTr3jmo/bR6ocnXvHNR+2j1RMgGbAhuTr3jmo/bR6ocnXvHNR+2j1RMgGbAhuTr3jmo/bR6ocnXvHNR+2j1RMgGbAhuTr3jmo/bR6ocnXvHNR+2j1RMgGbAhuTr3jmo/bR6ocnXvHNR+2j1RMgGbAhuTr3jmo/bR6olmW9yyhBrU4aSxrWeTP95j7AIiIAeGy39n9F/uT84x7jw2W/s/ov9yfnGJxegnvj0lPUtQAA5qAAAAAAAAAAAVLaf8AFmN9bU3/ADrItoqW0/4sxvram/51kbOTdPR3x6pjTDKABgVytx7epy5spuW6ygyI0wYT0t3ieCw2yhSz/iRcPCNpDPFT2g3+zYaKClUVUyTWKrGpcdvDhI1OrIjUa0trJOlOpRErSStONRDH7rlDNJq7BufBGRfFSqZ/w7G/cImrRT2q3FZc+nlKjUi3qsuozWqrTpcB51fYrzTJNpeaTrIlvajPmLSXhGMzqEhT9t9l1S4mKHGqzi5785+mN6oMhLKpbJrJ1jfG2Te8LdLPRqyZFkiMjIzjLP2/25c9t3BcEpEyg0akTXYpzKpCkR230IdUyS0KcbSSlKcQpO7QalpPSlREo9IhrX2M1umQNmUaoSqe6m36nPrdVJpxaifmPok6TaygtREuW4ozVpPgXAxXz2DXbUdidvWjUnaR21t6rM1Bh2HUpTLVS0LWtSnHUNodjuKU4peW9elSUmRn4Mb1DYx7erIRT0zHarJjkqoopJRpFMltSuy1tG6212OponSNSCNSe9wrhjOSGdE2u2xOuFuhMSZzlYUxHkrhlSpZOMNv6t0p4t1+hI9Cs7zTp4asZLNToWxl+BXLIqJxIMEqZMmVSqtlUZNQekTHI5x2F9kPp3j2ltayNSzSZYSSSxzTtJ2e1ONUtplQelx2ZtzPpKC8walHHYbhtsta8kXfE4Tq8Fku/LjzibyM0tsdnnQ6HWO3H+rq3HelU97sZ79M0yyp5xeNGUkTaFKyoizwIsmZEeJTNu9lVhqeuHU5LhwqaqsLbXTZTa3YaS4vMpW2RvI4kWW9XEyLnMhoraLs0vS3tmMBNWKgwodBtJy0aaxS5bz7jk2aqLCS+ZrZQRFoyRJLJpNR8VZ4bBr2xu7r2gXDJqcijUGqLteXbNEh0x92RHipfJO8dcdW22ozM22iIko7wknxUZ8IvI2Pst2gNbT7IplxNU2dSezGkuKhz4zrK2zUklERG4hG8ThRd+gjQfHCjwLYIO04VRatGDCrEOBT5zbG4cjUx9UiO2kspSSFuNoNRaSTzoLB5LiRZOn7OtgdC2a19VXp0jeyFMKY09p6VF71RkZ9/FhsufJLhqx85Hwxlzjzv/bZD2fbSqTQ6krc0ZdFl1WfJahSJTrWh1lto8MkrQjCnzUtScFoLinwzNy7arMtNMdU+s6yfhlUU9gRXpmiIfEpC9yhe7Z5/wBIvCeB8eBip3ns9vuobQLnrNDeoDcatUaPQ2ZU9543qe0g3VuOpZS2aXVKU+rvDWkv0aDNR5NJVqH7l86LdxIaaZrdoyadTaXIYmVydDcQxEZJnQuOyW5lpUktWl00kSlr5yPAxvV1C51LbA5K2us2jSXGY1OgU5FWq1VmU2S6wbTmpTaEPJNDTRGht1W+WpScp0kRqJRJlou3mxplPq85NZcai0qnqq0hcmBJZ1Q05zIaJbZG83wwSmtRGZkRZMyzQFbPJ21WBttJjeUZi4zZolLkSWFtpXHjRiTq08DNpTzkhOS505MskZGeRd+xi69pCKpPriqJTZ8qBFobNOgSHXozMHsxp6Yo3VNIUpbiGySlGgkp0kRqPUZkvIv0nbTaUOmRZ7s2aluY8piGyVKlqkTFEglmphgmt48gkqI942lSePOLTQa7BuaiwqtTHyk0+ayl9h4kmnWhRZI8KIjI/wBxkRl4Rqva9sfrF437Q7npKmZRw6dIprkN6tzqQaSccbXvEPRCNSv1DJTaiwotPEjSQ2tRaNCt2kQqXTo6IkCGylhhhsu9bQksERfyIZRe/OM0eGy39n9F/uT84x7jw2W/s/ov9yfnGJxegnvj0lPUtQAA5qAAAAAAAAAAAVLaf8WY31tTf86yLaKntNSZ2wyfgRVKctR/MRTWTMxs5N09HfHqmNMMkAAbSAAAAAAAAAAAAAAAAAAAAAAAAAAAB4bLf2f0X+5PzjHuPHZck07P6HnmVHJZH85GZmR/zIyEYvQz3x6SnqWkAAc1AAAAAAAAAAAPCdBj1KG9ElMokRnkGhxpwspUk+cjHuAmJmJvApzljVJvCIl0zWmE8EpfjsvKIscC1mkjV/E8n85mPnkTW+lsjqLHoFzAbXGsXZ4RuTeVM5E1vpbI6ix6A5E1vpbI6ix6BcwDjWLs8I3JupnImt9LZHUWPQHImt9LZHUWPQLmAcaxdnhG4upnImt9LZHUWPQHImt9LZHUWPQLmAcaxdnhG4upnImt9LZHUWPQIlm3LhcuuZTjvVg2GoTEhLCIzJy0qW46k1LRpwTZkhJJPnNSXC8BDZIr0Z0zv+ot72lGRUyKrdNl/rAsuyOLh/1J4wj/AIidDjWLs8I3F0byJrfS2R1Fj0ByJrfS2R1Fj0C5gHGsXZ4RuLqZyJrfS2R1Fj0ByJrfS2R1Fj0C5gHGsXZ4RuLqZyJrfS2R1Fj0ByJrfS2R1Fj0C5gHGsXZ4RuLqZyJrfS2R1Fj0ByJrfS2R1Fj0C5gHGsXZ4RuLqciwpkn9FUrjmTYiuDkdtlpknS8KVKSnURH/wAJkf7xbmWW47KGmkJaabSSUIQWEpIuBERFzEPsBTiYteJ70/j0Re4AAKkAAAAAAAAAAAAAAAAAAAAAAAAAAACuxjPuhVIs0bT2ri4Jr4SzvZH+1/8AY/q/+PfCxCuxtfdBqWW6STfauLhxv4RM97IyTn/slw0f8RvALEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArsZKi2hVJWijkk6XFIlN/CRnvZHB3/2ObR/xG8LEOM7e/8AETsmubYV0eLYtynPnojUlhKabFTUVyyfeJTLqjk43SdaDSWckpTpnzkA7MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFSk3xJfedKjUddUjtqNs5S5CWW1qI8HoyRmoiPJZxjJHgzFolKNEZ1STwZIMyP8AkKFs+IisK28ERf6tjc390kbuBRTNM11Re1o9dXcmNF2dyxuLos3+Jp9QOWNxdFm/xNPqCRAX2wuzj928vsR3LG4uizf4mn1A5Y3F0Wb/ABNPqCRALYXZx+7eX2I7ljcXRZv8TT6gcsbi6LN/iafUEiAWwuzj928vsR3LG4uizf4mn1A5Y3F0Wb/E0+oJEAthdnH7t5fYjuWNxdFm/wATT6g5/oHuclUH3UFV2vN26wrstg3GaV2akiZmrLS6/q04PUnJ4x+stR54EOkQC2F2cfu3l9iO5Y3F0Wb/ABNPqByxuLos3+Jp9QSIBbC7OP3by+xHcsbi6LN/iafUDljcXRZv8TT6gkQC2F2cfu3l9iO5Y3F0Wb/E0+oHLG4uizf4mn1BIgFsLs4/dvL7EdyxuLos3+Jp9QOWNxdFm/xNPqCRALYXZx+7eX2I7ljcXRZv8TT6gy6berypjMar0lyk79ZNsv79DzKlnzINRYNKj5iyWDPhnJkR+wr1/nptaSov1kusLSfzGTyDI/5GRDKnDwsSqKMyIv3/AJlMc82bEAAHJYgAAAAAAAAAPGZ70f8A7Cv+goez/wCIdt/Vsb8pIvkz3o//AGFf9BQ9n/xDtv6tjflJHQwOhq749JZdSfFeq+0W07frLNIqlz0am1Z7G6gS6g00+5nm0tqUSjz4MELAszJJmRZMi4F84579yhZdu3ZsapV2Vmk0+t3LX5D9SqlRnRkPPLlb9ZaTNRGaSb0klKS4J08BMzz2hi6FAc91+7r/ALvqm1Co25dLNsU6yXVRIlOVTmZCag+3FRIcVIWsjUlCt4SC3ZpMiIzyZ8BAsbUL52mHdlTol1LtOn06z6VckWIzTo8hW+kxn3TbWt1Bmbf6IiMsaj4YUnBkcZw6hWtLaFLWokoSWTUo8ERfOMalVaDXabGqFNmR6hAkoJ1iVFdS606g+ZSVpMyUR/ORjnm1b8vVuobNnq5caK5Av63pU5+n9gMsN095EVuQncKQWs04WpBk4pR8CPJcxVPZBXL02YbJtilcO50Vq2K27TaI/b71Paa7FRJ7xpxl5PfqUhWnUSzUSiNWNPAM4dYwKxAqjsxqFNjS3Yb3Y8lDDqVqYd0krQsiPvVYUk8HxwZH4RljlGPel40CHcMGnXAwiqv7U2beVVXKTFJa4zsVgzNxDaEJcWWvgs++PSkjUZFgSN0baLy2XN7RKA9UVXbV6ZMo0Wj1CRDYbezUTUjDiEbppRtm2s0/qErKSUZFkxGdA6dGHJrNPh1KHT350ZioTScVFiuPJS6+SCI1mhBnlRJJSTPBHjJZ5xzY7tY2o7LKDd1duOk1qr2/T6G7MYl3FFp0R1E8loS20RQnlkppRLMzM0kadHOeRmNW5d9B90Jsjcu68CumVJgVlW7RT2YrUVzcsa0tG2RGpB5SRa8q73OeOCnOG6ra2q2Vec44Vv3hQK7MJJqOPTamxIcwXOelCjPAtI4B2KPR7ot7YLQI9oLtyr017lByploYb7YRYprN9mMpCjcdUslpSpCtOE5UZGRZGz7C2sbYb8iUC8aXSa3LptVltOqpC4VMRS0QVO6VaJHZPZW8S3lWpScGpONBEfDGK7jq8Bzlbe0S8Yd4XbT7vuaTR6421Un6Vbj1IZRDkxm8mw/ElacumlGlS0qUZkZnlKSIYtqX5f1vWxsbu2s3cq5oV5u0+BUaVIp0dgmVy45rQ8ytpCVEaVJLUStRGRqMiTwIss4dLgOW4G1i/j2a0fbDIuJlVCn1Zhpy0O17RNNQXppRUkl/G9N9JKSszNWnOS04H5UtpW0Gn2lel9crSXCtq8ZFKboXa2OTMmEmoJZ0OOad5rJDmEqSaf1C1EozMwzoHUoDQcW/bopO3SoU277jlW9SXZq00KklSWlwKvFKPqIkTMGtMkl6lG2ai4JwlJ5yVMsLaxthvyJQLxpdJrcum1WW06qkLhUxFLRBU7pVokdk9lbxLeValJwak40ER8GcOrxXdoHxTmf22fzUCxCu7QPinM/ts/moGzgdLT3x6sqdMNigADjMQAAAAAAAAAHjM96P/wBhX/QUPZ/8Q7b+rY35SRfJnvR/+wr/AKCh7P8A4h239WxvykjoYHQ1d8eksupPjUEn3MtB7cVKTS7juu3KZU5Kpk6hUWrHGgvuqPLitJJ1t6z/AFt2tORt8BlMROli1befueKFeVbrE86zcFFarjSGa1T6ROJmPU0pToLfEaFKIzRhBm2pBmksGZiYjbG6BBnXRIiqlRUXBSY1FfjNKQTUeOw2622TJacpPS8rnNRcE8Cweb0Ai0ChMbGKJHKxSTKnnyOp7tNgZcR+lbcjpjqN3vOKtCCMjTpLOeGOAr1ne5mt60JFt5rtx1um25pXSaTVpyXYkR1KTSl0kJbSalkSlY1GZJ1HpJPDG3gC0DXDuwigPSZD5zKkS37qau9RE63gpbbbbaUF3n+yw2nJfrZM++HrcWwu2LsmXm/VkSpiLqjwmJrCnSSlrsXWbK2TSRKQslL1ZNR8UpxjjnYQBaBryj7FYEWhV2j1y4rivSBWIhQZDVxTUvElnCiwgkIQSVHqPK8ajwWVcCEbaXue6dat0W/XXLrumvSaCxIjU9mszm3mmmnkpSpOCaSZ4JCcGZ6uHEzwQ2qAWgavje56tyFs6tS0Y82qMN2vIalUqrNutlOjuIUZ6tW70GSiUpCkmjBpUZY8I/bU2AUqyK0zJolxXLT6KxKXMZtlmoEVMaWszNRJRo16DUpSt3r0ZP8AVGzwDNgakquwKKqpz6+5XbhuOqMxqgVKg1achyPCdktqSvdFoSZZJRoLWpRJSeCwITYt7nNFuW9s+qF1VWvVKs2/TI5MUSoz23oNMl7gm3DaQ2kiUacrSk1KWSSPvT5jG9gDNgalje5ptmLWIzxVOuOUGLUjq8e11zEnS2ZWs3CWlvRrwThmskGs0Eo86RJzdhFAn2Rc9rOTKkVPuCru1qU6l1veoeckJkKS2ejBI1oIiIyM8Z454jY4BaBrmdsQp1WviJcdTuC4am1DnlVIlElzUqgRpJINCXEI0EstJKVhOs0kZmeBjWpsApVkVpmTRLiuWn0ViUuYzbLNQIqY0tZmaiSjRr0GpSlbvXoyf6o2eAWgBXdoHxTmf22fzUCxCu7QPinM/ts/moGxgdLT3x6sqdMNigADjMQAAAAAAAAAH4pJLSaVFkjLBkNdU9E6y6dGo79Knz2YTaWI8yC0TqXWkkRINREeUqxwMsYyRmR8RsYBsYWNwcTExeJTEtfcqnPEFd6goOVTniCu9QUNggL+M0fJ5pvGpr7lU54grvUFByqc8QV3qChsEA4zR8nmXjU19yqc8QV3qCg5VOeIK71BQ2CAcZo+TzLxqa+5VOeIK71BQcqnPEFd6gobBAOM0fJ5l41NfcqnPEFd6goYiNoUZyrvUpNJrKqiyw3JcjFBVrS0tS0oWZfMam1kX9kxswa8phl/pBXIWks8l6X32eJ/0uof/f5hxmj5PMvGp9cqnPEFd6goOVTniCu9QUNggHGaPk8y8amvuVTniCu9QUHKpzxBXeoKGwQDjNHyeZeNTX3KpzxBXeoKDlU54grvUFDYIBxmj5PMvGpr7lU54grvUFByqc8QV3qChsEA4zR8nmXjU19yqc8QV3qCh+Ox5t6pagFS5tOgb5t2TJnNk3lCFpXu0IzqNStOMmRERGZ5M8EewgEcZiOeim095eAAAaLEAAAAAAAAAAAAAAAAAAAAAAAAAAAa+pqjPb9cSdZGRWxTD0ZPh/Sp/H5uOP48OPgGwRrymKI/dBXGnSWStelnq45P+l1Dh/8AfnAbDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa8pijP3QdyJ4YK16WfMWffdQ8P8AIbDGv6ahRbfbiV8k7ZphFz8/ZU/P7vCXNx+fwANgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8M8Fk+BCvXvekWyqT2S6g5Mt093FiIVpU8vHz8dKS51KweC8BmZEehq/WqldrynK1MXLQZkaYaO8jN/uJsuf+K9R/vHXyL2biZZGffNp17oT3ujHK/TGVmldSiIUXOlT6SMv+Y+eUdJ8aQusI9I5eTRaeksJgxiL5iZT6B+9p4H0KN90n0Dtcg4faT4f9ReHUHKOk+NIXWEekfzCsX3HUOL7s+Vb05Ud2wKQ6VbTJdcSbMiKasssaj4KM194oi44Qs/AOne08D6FG+6T6A7TwPoUb7pPoDkHD7SfD/peHUHKOk+NIXWEekOUdJ8aQusI9I5f7TwPoUb7pPoDtPA+hRvuk+gOQcPtJ8P+l4dRs1ymyFkhqoRXFn8lDyTP/qM4cmnRqeosHBjGXPxZT6BOW1ctWsx1CqTJUcVONVOkLUqOsvmIuds/mUnm4ZJRFgU4vsKYpvhV3nVMW87nM6WAQ9q3RDu+jt1CFqSk1G24y4RE4y4XOhRF4eY/mMjIyyRkYmB5euirDqmiqLTAAADAAAAAAAAAAAAAAAAAAAAAAAAAAABz1tIq663f9TNR5Zp2mEwWT4d6lbh4+c1KIv4ISK8JS8YSqdflxsLIy1yikIMy4KS4hKsl/PUX8UmIsfT8limnJ8OKdFo9EVaQDMkkZmeCLiZmAh7zpEi4LPrtLiOkxLmwH4zLpnjQtbakpV/IzIxsTMxEzDFEUTa3aVxVlql0+sIflvGpLGWXENyDTxUTTikkhzBEZ94o+BGPKkbZLPrs+FDg1gnnZrhsx1nGeQ046WTNsnFIJGvgfeZ1fuGutmFs06Uu16dVrdvWLWKQTbi+2UuWumxpDSNOps1Om0pJ8SSSCPgrGCIfFHtmrs7H9ncNVKmomxLojyH45xlk4y2U5xSnFJxlKdCsmZ8MHnmHMpx8aYiZiOudE7Obv55StW1fbtR7FpNZYp06PKuOCTZFFcjuusoWpScIcWgiSlRpMzJJrI+YbSHNNxRqxRtmt82W5a1cm1iZU5EtmdCgLfYmNuySdS4bieGokYI0nxLTzGOlhfgYleJXVnao5tXPPnoAAAbqFu2Q1dVKvwoWrEeqx1JUj53mu+Qr93eG4R/PhPzEN8DnvZlCXP2k0g0FwhtSJazxwItG6Lj85m7/wAj+YdCDw3tqKYyqJjTMRfz/FlnVAAAOAgAAAAAAAAAAAAAAAAAAAAAAAAAAGvtqtgu3G2zV6Y2S6tEQba2c47JZ4noI/AsjPKc8OKiPGrUWiqrSabc9Ofp1Ugsz4ilEl+HNZyRKSZHpW2ouCiMi4GWSMh1sK3cuzugXY92RUIBdmEREUuOtTL2C5iNaDI1EXzKyX7h6HIPakZPRwONF6fTZthOnS5K7i1gn/8AhlC/D2vVGVS9ldm0SexOp9rUiFNYVqakMQm0LQfzkZFkh0ErYFRjUZprFbbT4Ek+0eP5m2Zj87gVI8d1z75n2Q7Ee0sgjniP2ottanAbY7gVI8d1z75n2QdwKkeO6598z7IW8sZJrnwM3a1OKjJ2QWNMkuyH7Rorz7qzcccXBbNS1GeTMzxxMzHQ3cCpHjuuffM+yDuBUjx3XPvmfZDCr2rkVfvc/wBDN2udVbGbCUeTs2hmeMcYDXqiz02nRaPFiUumQkstkW6iwIbZEZ/8KEF//ObnPgNyt7BKKlRGurVl5Oc6VSG0+a2Ri22zYtDtDWqlwEMvrLSuS4pTryy+Y3FmajLPgzj9wor9r5LhRM4NN57rFoROzKxV2hT35E3QqrztJv6DylpCc6GyPw4yZmfhNR+DAuoAPI42NXj4k4lc88gAAKQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH/9k=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workflow = StateGraph(OverallState)\n",
    "workflow.add_node(\"PlanAgent\", plan_agent)\n",
    "workflow.add_node(\"solve\", builder.compile())\n",
    "workflow.add_node(\"feedback_node\", human_feedback)\n",
    "# workflow.add_node(\"should_continue\", should_continue)\n",
    "workflow.add_node(\"CombinedResponse\", combine_answers)\n",
    "\n",
    "workflow.add_edge(START, \"PlanAgent\")\n",
    "# workflow.add_edge(\"PlanAgent\", \"solve\")\n",
    "workflow.add_conditional_edges(\"PlanAgent\", parallelize, [\"solve\"])\n",
    "workflow.add_edge(\"solve\", \"feedback_node\")\n",
    "workflow.add_conditional_edges(\"feedback_node\", should_continue, [\"PlanAgent\", \"CombinedResponse\"])\n",
    "workflow.add_edge(\"CombinedResponse\", END)\n",
    "\n",
    "graph = workflow.compile(interrupt_before=['feedback_node'], checkpointer=MemorySaver())\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8749033a-90c7-4a8b-90ad-ee4ec0968c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Event: {'query': 'add 2 and 3, multiply 4 and 6, and divide 6 by 2 and return mean of all the answers', 'answers': []}\n",
      "Event Keys: dict_keys(['query', 'answers'])\n",
      "query: add 2 and 3, multiply 4 and 6, and divide 6 by 2 and return mean of all the answers\n",
      "answers: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Event: {'query': 'add 2 and 3, multiply 4 and 6, and divide 6 by 2 and return mean of all the answers', 'tasks': ['add 2 and 3 and return the result', 'multiply 4 and 6 and return the result', 'divide 6 by 2 and return the result', 'calculate the mean of the previous results and return the result'], 'answers': []}\n",
      "Event Keys: dict_keys(['query', 'tasks', 'answers'])\n",
      "query: add 2 and 3, multiply 4 and 6, and divide 6 by 2 and return mean of all the answers\n",
      "tasks: ['add 2 and 3 and return the result', 'multiply 4 and 6 and return the result', 'divide 6 by 2 and return the result', 'calculate the mean of the previous results and return the result']\n",
      "answers: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Calling add function with 2 and 3\n",
      "INFO:root:Tool returned 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Calling add function with 10 and 20\n",
      "INFO:root:Calling add function with 30 and 40\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Tool returned 70\n",
      "INFO:root:Tool returned 30\n",
      "INFO:root:Tool returned 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "At key 'answer': Can receive only one value per step. Use an Annotated key to handle multiple values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[250], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pass the extracted content (a string) to the AgentState\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# agent_state = AgentState(query=query)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m thread \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m     10\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query},\n\u001b[1;32m     11\u001b[0m     thread,\n\u001b[1;32m     12\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Print the entire event object for inspection\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull Event:\u001b[39m\u001b[38;5;124m\"\u001b[39m, event)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# If event is a dictionary (which is common), you can print its keys and values\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1292\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     get_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m-> 1292\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1299\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1300\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     ):\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m output()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/pregel/loop.py:325\u001b[0m, in \u001b[0;36mPregelLoop.tick\u001b[0;34m(self, input_keys, interrupt_after, interrupt_before, manager)\u001b[0m\n\u001b[1;32m    317\u001b[0m     print_step_writes(\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep,\n\u001b[1;32m    319\u001b[0m         writes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_keys,\n\u001b[1;32m    323\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m mv_writes \u001b[38;5;241m=\u001b[39m \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer_get_next_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# apply writes to managed values\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m mv_writes\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/pregel/algo.py:250\u001b[0m, in \u001b[0;36mapply_writes\u001b[0;34m(checkpoint, channels, tasks, get_next_version)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m get_next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m             checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m][chan] \u001b[38;5;241m=\u001b[39m get_next_version(\n\u001b[1;32m    252\u001b[0m                 max_version,\n\u001b[1;32m    253\u001b[0m                 channels[chan],\n\u001b[1;32m    254\u001b[0m             )\n\u001b[1;32m    255\u001b[0m         updated_channels\u001b[38;5;241m.\u001b[39madd(chan)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langgraph/channels/last_value.py:38\u001b[0m, in \u001b[0;36mLastValue.update\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt key \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: Can receive only one value per step. Use an Annotated key to handle multiple values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mInvalidUpdateError\u001b[0m: At key 'answer': Can receive only one value per step. Use an Annotated key to handle multiple values."
     ]
    }
   ],
   "source": [
    "# query = \"evalute 2+3, 4*7 & 5/0?\"\n",
    "query = \"add 2 and 3, multiply 4 and 6, and divide 6 by 2 and return mean of all the answers\"\n",
    "\n",
    "# Pass the extracted content (a string) to the AgentState\n",
    "# agent_state = AgentState(query=query)\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "\n",
    "for event in graph.stream(\n",
    "    {\"query\": query},\n",
    "    thread,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    # Print the entire event object for inspection\n",
    "    print(\"Full Event:\", event)\n",
    "\n",
    "    # If event is a dictionary (which is common), you can print its keys and values\n",
    "    if isinstance(event, dict):\n",
    "        print(\"Event Keys:\", event.keys())\n",
    "        for key, value in event.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "    # Optionally, if event has specific known attributes, you can print them like this:\n",
    "    if 'messages' in event:\n",
    "        for message in event['messages']:\n",
    "            print(\"Message Content:\", message['content'])\n",
    "\n",
    "    # Print the last message or specific components\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae7d6f-50d1-4663-bd0f-f2da5e604c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc9950-38d1-4b73-af08-adfa4d3084c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f33da-9d55-4f96-977b-27c68ff3d7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288bb52-f9d6-4de5-961f-257bdea01998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd4677-c2e8-4928-895f-73e6fc367c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f649f-0899-4f12-932d-7a434be4d84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74009f-37c0-4e33-ac59-e70f27c341dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd7cd2-3d27-4113-9066-05e73222e61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e23821-08b3-4fc6-b8f7-810ae9dc1a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469cea4-22c3-478a-a4a0-ef5420078854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67125e9-e0dd-4d34-a534-24d48221893c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d40ae5-e9ae-48e8-8cfe-a1f4251ef977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c5ef6-2830-4fba-b300-f234e621bdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c38131-050e-4845-b8f0-310aacf666dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430d951-d717-467b-a9c5-0fedb4dc5019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9d54c-3e8d-49bf-9253-b991f6754d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e5e33-3e44-4dbb-a663-537a8ce9ed61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
